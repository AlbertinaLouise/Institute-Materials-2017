# Week 2 - Day 3

## Week 2, Day 3: Wednesday, July 19

### Synopsis

Week 2, Day 3 expands upon the idea of digital editions as text processing pipelines. After a short recap of day 2, we continue with the step normalization. We will show how these two pipeline stages prepare texts for automated collation. The process of automated collation is also discussed from a modeling perspective (GM). Participants learn that their research goals and questions influence the computational pipelines.

### Legend

* **Presentation:** by instructors
* **Discussion:** instructors and participants
* **Talk lab:** participants discuss or plan in small groups
* **Code lab:** participants code alone or in small groups

-------

### 9:00-10:30: Normalization 1

#### Topics and Activities
* Short recap of Day 2: computational pipelines / modeling / processing / tokenization
* Basic normalization
	* Plain text normalization: lower/upper casing, whitespace, UniCode, punctuation etc.
	* NLTK
	* Regular expressions
	* Basic XML normalization: transforming XML to a stream of normalized (word) tokens
* **Hands-on exercise: [NLTK; regular expressions]**

#### Outcome goals
* Understanding the principles of basic text transformations like normalization and how they serve different objectives

### 10:30-11:00: Coffee 

### 11:00-12:30: Modeling: Collation

#### Topics and Activities
* Modeling and collation
* Collation within editorial theory
* Alignment (after tokenization/normalization in the GM)
* Collation practice 
	* plain text
	* creating witnesses
	* variant graph as a model
	* visualization of collation output
* Tokenization and normalization for collation purposes

#### Outcome goals
* Normalize, tokenize, and collate text
* ***[some text here]***

### 12:30-14:00: Lunch (on your own)

### 14:00-15:30: Challenging Textual Phenomena / Introducing Text as Graph (TAG)

#### Topics and activities

* Markup as an expression of a data model; making the implicit explicit and machine-actionable
* How XML copes with limitations of the tree as a document model
* What’s so bad about work-arounds and relying on application-level semantics?
* Research-driven annotation: 1) What are the inherent properties of the text, and 2) What do I need for my research? Research questions → data model (including query facilities) → markup/annotation.
* Introduction to Text as Graph (TAG)
* Modeling textual phenomena such as overlap and discontinuity in XML, LMNL, and TAG
* Using a schema to bring markup semantics into the model at the application level
* LMNL ranges and TAG sets: similarities and differences: _Mrs. Warren’s profession_ as plain text, XML, LMNL, and in TAG

#### Outcome goals

* Fundamentals of TAG: hypergraph
* Modeling discontinuity

### 15:30-16:00: Coffee/tea

### 16:00-17:30: Normalization 2

#### Topics and Activities
* Normalization and markup
* Linguistic tools
* [etc.]

#### Outcome goals
* _[some text here]_